{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (3.11.0)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: langchain in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (0.0.332)\n",
      "Requirement already satisfied: nltk in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (4.34.0)\n",
      "Requirement already satisfied: pyaudio in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (0.2.14)\n",
      "Collecting keyboard\n",
      "  Downloading keyboard-0.13.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from SpeechRecognition) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from SpeechRecognition) (4.7.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from langchain) (2.0.22)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: anyio<4.0 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.52 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from langchain) (0.0.52)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from langchain) (1.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: click in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from nltk) (2023.8.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from transformers) (0.14.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.9.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\public\\downloads\\fullstackgpt\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Downloading keyboard-0.13.5-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.1/58.1 kB 1.5 MB/s eta 0:00:00\n",
      "Installing collected packages: keyboard\n",
      "Successfully installed keyboard-0.13.5\n"
     ]
    }
   ],
   "source": [
    "pip install SpeechRecognition langchain nltk transformers pyaudio keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SummarizationChain' from 'langchain.chains' (c:\\Users\\Public\\Downloads\\FullStackGPT\\.venv\\Lib\\site-packages\\langchain\\chains\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext_splitter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SummarizationChain\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# nltk의 punkt 패키지를 다운로드합니다.\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'SummarizationChain' from 'langchain.chains' (c:\\Users\\Public\\Downloads\\FullStackGPT\\.venv\\Lib\\site-packages\\langchain\\chains\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import SummarizationChain\n",
    "import nltk\n",
    "\n",
    "# nltk의 punkt 패키지를 다운로드합니다.\n",
    "nltk.download('punkt')\n",
    "\n",
    "# 음성 인식 초기화\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "def transcribe_audio():\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"회의를 시작하세요. 말하는 내용을 듣고 있습니다...\")\n",
    "        audio = recognizer.listen(source)\n",
    "        print(\"음성을 인식 중입니다...\")\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio, language='ko-KR')\n",
    "            print(\"인식된 텍스트:\", text)\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"음성을 인식할 수 없습니다.\")\n",
    "            return \"\"\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"구글 음성 인식 서비스에 접근할 수 없습니다: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "def summarize_text(text):\n",
    "    # Langchain을 사용하여 텍스트 요약\n",
    "    llm = OpenAI(temperature=0.5)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    summarization_chain = SummarizationChain(llm=llm)\n",
    "    \n",
    "    summary = summarization_chain.run(chunks)\n",
    "    return summary\n",
    "\n",
    "def save_to_file(transcript, summary):\n",
    "    with open(\"meeting_notes.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"회의록:\\n\")\n",
    "        f.write(transcript + \"\\n\\n\")\n",
    "        f.write(\"요약:\\n\")\n",
    "        f.write(summary)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    transcript = \"\"\n",
    "    while True:\n",
    "        text = transcribe_audio()\n",
    "        if text:\n",
    "            transcript += text + \"\\n\"\n",
    "        if input(\"더 이상 말하지 않으시겠습니까? (y/n): \").lower() == 'y':\n",
    "            break\n",
    "\n",
    "    summary = summarize_text(transcript)\n",
    "    save_to_file(transcript, summary)\n",
    "    print(\"회의록과 요약본이 'meeting_notes.txt' 파일에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bt10470\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "회의를 시작하세요. 말하는 내용을 듣고 있습니다...\n",
      "음성을 인식 중입니다...\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import nltk\n",
    "\n",
    "# nltk의 punkt 패키지를 다운로드합니다.\n",
    "nltk.download('punkt')\n",
    "\n",
    "# 음성 인식 초기화\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "def transcribe_audio():\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"회의를 시작하세요. 말하는 내용을 듣고 있습니다...\")\n",
    "        audio = recognizer.listen(source)\n",
    "        print(\"음성을 인식 중입니다...\")\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio, language='ko-KR')\n",
    "            print(\"인식된 텍스트:\", text)\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"음성을 인식할 수 없습니다.\")\n",
    "            return \"\"\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"구글 음성 인식 서비스에 접근할 수 없습니다: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "def summarize_text(text):\n",
    "    # Langchain을 사용하여 텍스트 요약\n",
    "    llm = OpenAI(temperature=0.5)\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=\"다음 내용을 요약해 주세요:\\n{text}\\n\\n요약:\"\n",
    "    )\n",
    "    chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "    \n",
    "    summary = chain.run(text)\n",
    "    return summary\n",
    "\n",
    "def save_to_file(transcript, summary):\n",
    "    with open(\"meeting_notes.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"회의록:\\n\")\n",
    "        f.write(transcript + \"\\n\\n\")\n",
    "        f.write(\"요약:\\n\")\n",
    "        f.write(summary)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    transcript = \"\"\n",
    "    while True:\n",
    "        text = transcribe_audio()\n",
    "        if text:\n",
    "            transcript += text + \"\\n\"\n",
    "        if input(\"더 이상 말하지 않으시겠습니까? (y/n): \").lower() == 'y':\n",
    "            break\n",
    "\n",
    "    summary = summarize_text(transcript)\n",
    "    save_to_file(transcript, summary)\n",
    "    print(\"회의록과 요약본이 'meeting_notes.txt' 파일에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bt10470\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "회의를 시작하세요. 말하는 내용을 듣고 있습니다...\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m keyboard_thread \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mThread(target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m: keyboard\u001b[38;5;241m.\u001b[39mwait(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mesc\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m stop_program())\n\u001b[0;32m     60\u001b[0m keyboard_thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m---> 62\u001b[0m \u001b[43mtranscribe_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 음성 인식 시작\u001b[39;00m\n\u001b[0;32m     64\u001b[0m summary \u001b[38;5;241m=\u001b[39m summarize_text(transcript)\n\u001b[0;32m     65\u001b[0m save_to_file(transcript, summary)\n",
      "Cell \u001b[1;32mIn[2], line 22\u001b[0m, in \u001b[0;36mtranscribe_audio\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m회의를 시작하세요. 말하는 내용을 듣고 있습니다...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m running:\n\u001b[1;32m---> 22\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m음성을 인식 중입니다...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Public\\Downloads\\FullStackGPT\\.venv\\Lib\\site-packages\\speech_recognition\\__init__.py:465\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[0;32m    463\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_listen(source, timeout, phrase_time_limit, snowboy_configuration, stream)\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m--> 465\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[0;32m    466\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m a\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Public\\Downloads\\FullStackGPT\\.venv\\Lib\\site-packages\\speech_recognition\\__init__.py:535\u001b[0m, in \u001b[0;36mRecognizer._listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phrase_time_limit \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m-\u001b[39m phrase_start_time \u001b[38;5;241m>\u001b[39m phrase_time_limit:\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 535\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    537\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
      "File \u001b[1;32mc:\\Users\\Public\\Downloads\\FullStackGPT\\.venv\\Lib\\site-packages\\speech_recognition\\__init__.py:196\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[1;32m--> 196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyaudio_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Public\\Downloads\\FullStackGPT\\.venv\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import nltk\n",
    "import keyboard\n",
    "import threading\n",
    "\n",
    "# nltk의 punkt 패키지를 다운로드합니다.\n",
    "nltk.download('punkt')\n",
    "\n",
    "# 음성 인식 초기화\n",
    "recognizer = sr.Recognizer()\n",
    "transcript = \"\"\n",
    "running = True\n",
    "\n",
    "def transcribe_audio():\n",
    "    global transcript, running\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"회의를 시작하세요. 말하는 내용을 듣고 있습니다...\")\n",
    "        while running:\n",
    "            audio = recognizer.listen(source)\n",
    "            print(\"음성을 인식 중입니다...\")\n",
    "            try:\n",
    "                text = recognizer.recognize_google(audio, language='ko-KR')\n",
    "                print(\"인식된 텍스트:\", text)\n",
    "                transcript += text + \"\\n\"\n",
    "            except sr.UnknownValueError:\n",
    "                print(\"음성을 인식할 수 없습니다.\")\n",
    "            except sr.RequestError as e:\n",
    "                print(f\"구글 음성 인식 서비스에 접근할 수 없습니다: {e}\")\n",
    "\n",
    "def summarize_text(text):\n",
    "    # Langchain을 사용하여 텍스트 요약\n",
    "    llm = OpenAI(temperature=0.5)\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=\"다음 내용을 요약해 주세요:\\n{text}\\n\\n요약:\"\n",
    "    )\n",
    "    chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "    \n",
    "    summary = chain.run(text)\n",
    "    return summary\n",
    "\n",
    "def save_to_file(transcript, summary):\n",
    "    with open(\"meeting_notes.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"회의록:\\n\")\n",
    "        f.write(transcript + \"\\n\\n\")\n",
    "        f.write(\"요약:\\n\")\n",
    "        f.write(summary)\n",
    "\n",
    "def stop_program():\n",
    "    global running\n",
    "    running = False\n",
    "    print(\"프로그램이 종료됩니다.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Esc 키가 눌리면 stop_program 함수를 호출하는 스레드 시작\n",
    "    keyboard_thread = threading.Thread(target=lambda: keyboard.wait('esc') and stop_program())\n",
    "    keyboard_thread.start()\n",
    "\n",
    "    transcribe_audio()  # 음성 인식 시작\n",
    "\n",
    "    summary = summarize_text(transcript)\n",
    "    save_to_file(transcript, summary)\n",
    "    print(\"회의록과 요약본이 'meeting_notes.txt' 파일에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bt10470\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "회의를 시작하세요. 말하는 내용을 듣고 있습니다...\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m keyboard_thread \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mThread(target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m: keyboard\u001b[38;5;241m.\u001b[39mwait(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mesc\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m stop_program())\n\u001b[0;32m     60\u001b[0m keyboard_thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m---> 62\u001b[0m \u001b[43mtranscribe_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 음성 인식 시작\u001b[39;00m\n\u001b[0;32m     64\u001b[0m summary \u001b[38;5;241m=\u001b[39m summarize_text(transcript)\n\u001b[0;32m     65\u001b[0m save_to_file(transcript, summary)\n",
      "Cell \u001b[1;32mIn[6], line 22\u001b[0m, in \u001b[0;36mtranscribe_audio\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m회의를 시작하세요. 말하는 내용을 듣고 있습니다...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m running:\n\u001b[1;32m---> 22\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m음성을 인식 중입니다...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Public\\Downloads\\FullStackGPT\\.venv\\Lib\\site-packages\\speech_recognition\\__init__.py:465\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[0;32m    463\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_listen(source, timeout, phrase_time_limit, snowboy_configuration, stream)\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m--> 465\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[0;32m    466\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m a\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Public\\Downloads\\FullStackGPT\\.venv\\Lib\\site-packages\\speech_recognition\\__init__.py:535\u001b[0m, in \u001b[0;36mRecognizer._listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phrase_time_limit \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m-\u001b[39m phrase_start_time \u001b[38;5;241m>\u001b[39m phrase_time_limit:\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 535\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    537\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
      "File \u001b[1;32mc:\\Users\\Public\\Downloads\\FullStackGPT\\.venv\\Lib\\site-packages\\speech_recognition\\__init__.py:196\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[1;32m--> 196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyaudio_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Public\\Downloads\\FullStackGPT\\.venv\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import nltk\n",
    "import keyboard\n",
    "import threading\n",
    "\n",
    "# nltk의 punkt 패키지를 다운로드합니다.\n",
    "nltk.download('punkt')\n",
    "\n",
    "# 음성 인식 초기화\n",
    "recognizer = sr.Recognizer()\n",
    "transcript = \"\"\n",
    "running = True\n",
    "\n",
    "def transcribe_audio():\n",
    "    global transcript, running\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"회의를 시작하세요. 말하는 내용을 듣고 있습니다...\")\n",
    "        while running:\n",
    "            audio = recognizer.listen(source)\n",
    "            print(\"음성을 인식 중입니다...\")\n",
    "            try:\n",
    "                text = recognizer.recognize_google(audio, language='ko-KR')\n",
    "                print(\"인식된 텍스트:\", text)  # 실시간으로 콘솔에 출력\n",
    "                transcript += text + \"\\n\"\n",
    "            except sr.UnknownValueError:\n",
    "                print(\"음성을 인식할 수 없습니다.\")\n",
    "            except sr.RequestError as e:\n",
    "                print(f\"구글 음성 인식 서비스에 접근할 수 없습니다: {e}\")\n",
    "\n",
    "def summarize_text(text):\n",
    "    # Langchain을 사용하여 텍스트 요약\n",
    "    llm = OpenAI(temperature=0.5)\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=\"다음 내용을 요약해 주세요:\\n{text}\\n\\n요약:\"\n",
    "    )\n",
    "    chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "    \n",
    "    summary = chain.run(text)\n",
    "    return summary\n",
    "\n",
    "def save_to_file(transcript, summary):\n",
    "    with open(\"meeting_notes.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"회의록:\\n\")\n",
    "        f.write(transcript + \"\\n\\n\")\n",
    "        f.write(\"요약:\\n\")\n",
    "        f.write(summary)\n",
    "\n",
    "def stop_program():\n",
    "    global running\n",
    "    running = False\n",
    "    print(\"프로그램이 종료됩니다.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Esc 키가 눌리면 stop_program 함수를 호출하는 스레드 시작\n",
    "    keyboard_thread = threading.Thread(target=lambda: keyboard.wait('esc') and stop_program())\n",
    "    keyboard_thread.start()\n",
    "\n",
    "    transcribe_audio()  # 음성 인식 시작\n",
    "\n",
    "    summary = summarize_text(transcript)\n",
    "    save_to_file(transcript, summary)\n",
    "    print(\"회의록과 요약본이 'meeting_notes.txt' 파일에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bt10470\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "회의를 시작하세요. 말하는 내용을 듣고 있습니다...\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n",
      "음성을 인식 중입니다...\n",
      "음성을 인식할 수 없습니다.\n"
     ]
    },
    {
     "ename": "WaitTimeoutError",
     "evalue": "listening timed out while waiting for phrase to start",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWaitTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 64\u001b[0m\n\u001b[0;32m     61\u001b[0m keyboard_thread \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mThread(target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m: keyboard\u001b[38;5;241m.\u001b[39mwait(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mesc\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m stop_program())\n\u001b[0;32m     62\u001b[0m keyboard_thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m---> 64\u001b[0m \u001b[43mtranscribe_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 음성 인식 시작\u001b[39;00m\n\u001b[0;32m     66\u001b[0m summary \u001b[38;5;241m=\u001b[39m summarize_text(transcript)\n\u001b[0;32m     67\u001b[0m save_to_file(transcript, summary)\n",
      "Cell \u001b[1;32mIn[5], line 24\u001b[0m, in \u001b[0;36mtranscribe_audio\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m회의를 시작하세요. 말하는 내용을 듣고 있습니다...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m running:\n\u001b[1;32m---> 24\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphrase_time_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 타임아웃 및 구문 시간 제한 설정\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m음성을 인식 중입니다...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Public\\Downloads\\FullStackGPT\\.venv\\Lib\\site-packages\\speech_recognition\\__init__.py:465\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[0;32m    463\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_listen(source, timeout, phrase_time_limit, snowboy_configuration, stream)\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m--> 465\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[0;32m    466\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m a\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Public\\Downloads\\FullStackGPT\\.venv\\Lib\\site-packages\\speech_recognition\\__init__.py:495\u001b[0m, in \u001b[0;36mRecognizer._listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[0;32m    493\u001b[0m elapsed_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m seconds_per_buffer\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m>\u001b[39m timeout:\n\u001b[1;32m--> 495\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WaitTimeoutError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlistening timed out while waiting for phrase to start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    497\u001b[0m buffer \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mread(source\u001b[38;5;241m.\u001b[39mCHUNK)\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n",
      "\u001b[1;31mWaitTimeoutError\u001b[0m: listening timed out while waiting for phrase to start"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import nltk\n",
    "import keyboard\n",
    "import threading\n",
    "\n",
    "# nltk의 punkt 패키지를 다운로드합니다.\n",
    "nltk.download('punkt')\n",
    "\n",
    "# 음성 인식 초기화\n",
    "recognizer = sr.Recognizer()\n",
    "transcript = \"\"\n",
    "running = True\n",
    "\n",
    "def transcribe_audio():\n",
    "    global transcript, running\n",
    "    with sr.Microphone() as source:\n",
    "        # 주변 소음에 적응\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        print(\"회의를 시작하세요. 말하는 내용을 듣고 있습니다...\")\n",
    "        while running:\n",
    "            audio = recognizer.listen(source, timeout=5, phrase_time_limit=10)  # 타임아웃 및 구문 시간 제한 설정\n",
    "            print(\"음성을 인식 중입니다...\")\n",
    "            try:\n",
    "                text = recognizer.recognize_google(audio, language='ko-KR')\n",
    "                print(\"인식된 텍스트:\", text)  # 실시간으로 콘솔에 출력\n",
    "                transcript += text + \"\\n\"\n",
    "            except sr.UnknownValueError:\n",
    "                print(\"음성을 인식할 수 없습니다.\")\n",
    "            except sr.RequestError as e:\n",
    "                print(f\"구글 음성 인식 서비스에 접근할 수 없습니다: {e}\")\n",
    "\n",
    "def summarize_text(text):\n",
    "    # Langchain을 사용하여 텍스트 요약\n",
    "    llm = OpenAI(temperature=0.5)\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=\"다음 내용을 요약해 주세요:\\n{text}\\n\\n요약:\"\n",
    "    )\n",
    "    chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "    \n",
    "    summary = chain.run(text)\n",
    "    return summary\n",
    "\n",
    "def save_to_file(transcript, summary):\n",
    "    with open(\"meeting_notes.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"회의록:\\n\")\n",
    "        f.write(transcript + \"\\n\\n\")\n",
    "        f.write(\"요약:\\n\")\n",
    "        f.write(summary)\n",
    "\n",
    "def stop_program():\n",
    "    global running\n",
    "    running = False\n",
    "    print(\"프로그램이 종료됩니다.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Esc 키가 눌리면 stop_program 함수를 호출하는 스레드 시작\n",
    "    keyboard_thread = threading.Thread(target=lambda: keyboard.wait('esc') and stop_program())\n",
    "    keyboard_thread.start()\n",
    "\n",
    "    transcribe_audio()  # 음성 인식 시작\n",
    "\n",
    "    summary = summarize_text(transcript)\n",
    "    save_to_file(transcript, summary)\n",
    "    print(\"회의록과 요약본이 'meeting_notes.txt' 파일에 저장되었습니다.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
